{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cluster ID</th>\n",
       "      <th>Id</th>\n",
       "      <th>Site name</th>\n",
       "      <th>Address</th>\n",
       "      <th>Zip</th>\n",
       "      <th>Phone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>salvation army - temple / salvation army</td>\n",
       "      <td>1 n ogden ave</td>\n",
       "      <td>nan</td>\n",
       "      <td>2262649.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>salvation army - temple / salvation army</td>\n",
       "      <td>1 n ogden ave</td>\n",
       "      <td>nan</td>\n",
       "      <td>2262649.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>215</td>\n",
       "      <td>salvation army temple</td>\n",
       "      <td>1 n. ogden</td>\n",
       "      <td>nan</td>\n",
       "      <td>2262649.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>509</td>\n",
       "      <td>salvation army - temple / salvation army</td>\n",
       "      <td>1 n ogden ave</td>\n",
       "      <td>nan</td>\n",
       "      <td>2262649.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>510</td>\n",
       "      <td>salvation army - temple / salvation army</td>\n",
       "      <td>1 n ogden ave</td>\n",
       "      <td>nan</td>\n",
       "      <td>2262649.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1225</td>\n",
       "      <td>salvation army - temple / salvation army</td>\n",
       "      <td>1 n ogden ave</td>\n",
       "      <td>nan</td>\n",
       "      <td>2262649.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1226</td>\n",
       "      <td>salvation army - temple / salvation army</td>\n",
       "      <td>1 n ogden ave</td>\n",
       "      <td>nan</td>\n",
       "      <td>2262649.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1879</td>\n",
       "      <td>salvation army temple</td>\n",
       "      <td>1 n ogden</td>\n",
       "      <td>60640.0</td>\n",
       "      <td>2262649.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>2758</td>\n",
       "      <td>salvation army temple</td>\n",
       "      <td>1 n. ogden</td>\n",
       "      <td>60607.0</td>\n",
       "      <td>2262649.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>3255</td>\n",
       "      <td>salvation army - chicago temple corps communit...</td>\n",
       "      <td>1 n ogden avenue</td>\n",
       "      <td>60607.0</td>\n",
       "      <td>2262649.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>national louis university - dr. effie o. ellis...</td>\n",
       "      <td>10 s kedzie ave</td>\n",
       "      <td>nan</td>\n",
       "      <td>5339011.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>national louis university - dr. effie o. ellis...</td>\n",
       "      <td>10 s kedzie ave</td>\n",
       "      <td>nan</td>\n",
       "      <td>5339011.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>216</td>\n",
       "      <td>national louis university-dr. effie o. ellis h...</td>\n",
       "      <td>10 s. kedzie</td>\n",
       "      <td>nan</td>\n",
       "      <td>5339011.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>511</td>\n",
       "      <td>national louis university - dr. effie o. ellis...</td>\n",
       "      <td>10 s kedzie ave</td>\n",
       "      <td>nan</td>\n",
       "      <td>5339011.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>national louis university - dr. effie o. ellis...</td>\n",
       "      <td>10 s kedzie ave</td>\n",
       "      <td>nan</td>\n",
       "      <td>5339011.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Cluster ID    Id                                          Site name  \\\n",
       "0            0     0           salvation army - temple / salvation army   \n",
       "1            0     1           salvation army - temple / salvation army   \n",
       "2            0   215                              salvation army temple   \n",
       "3            0   509           salvation army - temple / salvation army   \n",
       "4            0   510           salvation army - temple / salvation army   \n",
       "5            0  1225           salvation army - temple / salvation army   \n",
       "6            0  1226           salvation army - temple / salvation army   \n",
       "7            0  1879                              salvation army temple   \n",
       "8            0  2758                              salvation army temple   \n",
       "9            0  3255  salvation army - chicago temple corps communit...   \n",
       "10           1     2  national louis university - dr. effie o. ellis...   \n",
       "11           1     3  national louis university - dr. effie o. ellis...   \n",
       "12           1   216  national louis university-dr. effie o. ellis h...   \n",
       "13           1   511  national louis university - dr. effie o. ellis...   \n",
       "14           1   512  national louis university - dr. effie o. ellis...   \n",
       "\n",
       "             Address      Zip      Phone  \n",
       "0      1 n ogden ave      nan  2262649.0  \n",
       "1      1 n ogden ave      nan  2262649.0  \n",
       "2         1 n. ogden      nan  2262649.0  \n",
       "3      1 n ogden ave      nan  2262649.0  \n",
       "4      1 n ogden ave      nan  2262649.0  \n",
       "5      1 n ogden ave      nan  2262649.0  \n",
       "6      1 n ogden ave      nan  2262649.0  \n",
       "7          1 n ogden  60640.0  2262649.0  \n",
       "8         1 n. ogden  60607.0  2262649.0  \n",
       "9   1 n ogden avenue  60607.0  2262649.0  \n",
       "10   10 s kedzie ave      nan  5339011.0  \n",
       "11   10 s kedzie ave      nan  5339011.0  \n",
       "12      10 s. kedzie      nan  5339011.0  \n",
       "13   10 s kedzie ave      nan  5339011.0  \n",
       "14   10 s kedzie ave      nan  5339011.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = pd.read_csv('../dat/schools_w_clusters.csv')\n",
    "raw = raw[['Cluster ID', 'Id', 'Site name', 'Address', 'Zip', 'Phone']]\n",
    "raw['Zip'] = raw['Zip'].astype(str)\n",
    "raw['Phone'] = raw['Phone'].astype(str)\n",
    "raw.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name max len = 95\n",
      "address max len = 43\n",
      "Zip max len = 7\n",
      "phone max len = 9\n"
     ]
    }
   ],
   "source": [
    "print('name max len =', raw['Site name'].str.len().max())\n",
    "print('address max len =', raw['Address'].str.len().max())\n",
    "print('Zip max len =', raw['Zip'].str.len().max())\n",
    "print('phone max len =', raw['Phone'].str.len().max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for a total of max length 154"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## defs\n",
    "The following insanity is how we need to convert into a useable Torch tensor of correct size and Variable...ness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.0181  0.5914  0.6572  0.6891  0.3115  0.8512  0.0298  0.4591  0.1530  0.7110\n",
       "[torch.FloatTensor of size 1x10]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Variable(torch.from_numpy(np.random.rand(10)).float()).view(1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extend_to_length(string_to_expand, length):\n",
    "    extension = '~' * (length-len(string_to_expand))\n",
    "    return string_to_expand + extension\n",
    "\n",
    "def record_formatter(record):\n",
    "    name = extend_to_length(record['Site name'], 95)\n",
    "    addr = extend_to_length(record['Address'], 43)\n",
    "    zipp = extend_to_length(record['Zip'], 7)\n",
    "    phon = extend_to_length(record['Phone'], 9)\n",
    "    \n",
    "    strings = list(''.join((name, addr, zipp, phon)))\n",
    "    characters = np.array(list(map(ord, strings)))\n",
    "    \n",
    "    return Variable(torch.from_numpy(characters).float()).view(1,len(characters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self, v_size=154, enc_size=50):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(v_size, 400),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(400, 200),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(200, 100),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(100, enc_size)\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(enc_size, 75),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(75, 100),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(100, 125),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(125, v_size)\n",
    "        )\n",
    "        \n",
    "        self.discriminator = nn.Sequential(\n",
    "            nn.Linear(enc_size*2, 100),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(100, 50),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(50,2),\n",
    "            nn.LogSoftmax()\n",
    "        )\n",
    "\n",
    "    def discriminate(self, input1, input2):\n",
    "        output = self.discriminator(torch.cat([input1, input2], dim=1))\n",
    "        return output\n",
    "    \n",
    "    def autoencode(self, vector):\n",
    "        return self.decoder(self.encoder(vector))\n",
    "    \n",
    "    def encode(self, vector):\n",
    "        return self.encoder(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2693, 6)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(740,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw['Cluster ID'].unique().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "model = SiameseNetwork()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 4s, sys: 8.05 s, total: 3min 12s\n",
      "Wall time: 28.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ae_loss = []\n",
    "\n",
    "model.train()\n",
    "\n",
    "# train autoencoder\n",
    "for epoch in range(1):\n",
    "    temp_loss = 0\n",
    "    \n",
    "    for i in range(raw.shape[0]):\n",
    "        # build data pairs\n",
    "        inpt = record_formatter(raw.iloc[i])\n",
    "\n",
    "        # forward\n",
    "        otpt = model.autoencode(inpt)\n",
    "        loss = criterion(otpt, inpt)\n",
    "        \n",
    "        # backprop\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # logging\n",
    "        temp_loss += loss\n",
    "\n",
    "    # logging\n",
    "    ae_loss.append(temp_loss.data[0]/raw.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 7s, sys: 5min 26s, total: 8min 34s\n",
      "Wall time: 1min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "disc_loss = []\n",
    "diff = 1\n",
    "model.train()\n",
    "\n",
    "# train discriminator\n",
    "for epoch in range(1):\n",
    "    temp_loss = 0\n",
    "    \n",
    "    for i in range(raw.shape[0]-diff):\n",
    "        # build data pairs\n",
    "        inpt1 = model.encode(record_formatter(raw.iloc[i]))\n",
    "        inpt2 = model.encode(record_formatter(raw.iloc[i+diff]))\n",
    "        label = 1 if (raw.iloc[i]['Cluster ID'] == raw.iloc[i+diff]['Cluster ID']) else 0\n",
    "        label = Variable(torch.LongTensor([label]))\n",
    "        \n",
    "        # forward\n",
    "        otpt = model.discriminate(inpt1, inpt2)\n",
    "        loss = criterion(otpt, label)\n",
    "        \n",
    "        # backprop\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # logging\n",
    "        temp_loss += loss\n",
    "\n",
    "    # logging\n",
    "    disc_loss.append(temp_loss.data[0]/raw.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't forget to Exp the output b/c LogSoftmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.4388  0.5612\n",
       "[torch.FloatTensor of size 1x2]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(model.discriminate(inpt1, inpt2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ae loss = [314.7897326401782]\n",
      "disc ls = [315.39150111399925]\n"
     ]
    }
   ],
   "source": [
    "print('ae loss =', ae_loss)\n",
    "print('disc ls =', disc_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 2.3750e-13  1.0000e+00\n",
       "[torch.FloatTensor of size 1x2]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inpt1 = model.encode(record_formatter(raw.iloc[0]))\n",
    "inpt2 = model.encode(record_formatter(raw.iloc[4]))\n",
    "\n",
    "model.discriminate(inpt1, inpt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SiameseNetwork (\n",
       "  (encoder): Sequential (\n",
       "    (0): Linear (154 -> 400)\n",
       "    (1): ReLU (inplace)\n",
       "    (2): Linear (400 -> 200)\n",
       "    (3): ReLU (inplace)\n",
       "    (4): Linear (200 -> 100)\n",
       "    (5): ReLU (inplace)\n",
       "    (6): Linear (100 -> 50)\n",
       "  )\n",
       "  (decoder): Sequential (\n",
       "    (0): Linear (50 -> 75)\n",
       "    (1): ReLU (inplace)\n",
       "    (2): Linear (75 -> 100)\n",
       "    (3): ReLU (inplace)\n",
       "    (4): Linear (100 -> 125)\n",
       "    (5): ReLU (inplace)\n",
       "    (6): Linear (125 -> 154)\n",
       "  )\n",
       "  (discriminator): Sequential (\n",
       "    (0): Linear (100 -> 100)\n",
       "    (1): ReLU (inplace)\n",
       "    (2): Linear (100 -> 50)\n",
       "    (3): ReLU (inplace)\n",
       "    (4): Linear (50 -> 2)\n",
       "    (5): Softmax ()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['fc1.0.weight', 'fc1.0.bias', 'fc1.2.weight', 'fc1.2.bias'])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 154])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inpt1.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "nan\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_calc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       " \n",
       " Columns 0 to 12 \n",
       "   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
       " \n",
       " Columns 13 to 25 \n",
       "   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
       " \n",
       " Columns 26 to 38 \n",
       "   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
       " \n",
       " Columns 39 to 51 \n",
       "   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
       " \n",
       " Columns 52 to 64 \n",
       "   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
       " \n",
       " Columns 65 to 77 \n",
       "   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
       " \n",
       " Columns 78 to 79 \n",
       "   nan   nan\n",
       " [torch.FloatTensor of size 1x80], Variable containing:\n",
       " \n",
       " Columns 0 to 12 \n",
       "   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
       " \n",
       " Columns 13 to 25 \n",
       "   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
       " \n",
       " Columns 26 to 38 \n",
       "   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
       " \n",
       " Columns 39 to 51 \n",
       "   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
       " \n",
       " Columns 52 to 64 \n",
       "   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
       " \n",
       " Columns 65 to 77 \n",
       "   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
       " \n",
       " Columns 78 to 79 \n",
       "   nan   nan\n",
       " [torch.FloatTensor of size 1x80])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.forward(inpt1,inpt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y can be no greater than 2-D, but have shapes (1,) and (1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-e870b0f35dc1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_holder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   3238\u001b[0m                       mplDeprecation)\n\u001b[1;32m   3239\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3240\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3241\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3242\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1708\u001b[0m                     warnings.warn(msg % (label_namer, func.__name__),\n\u001b[1;32m   1709\u001b[0m                                   RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1710\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1711\u001b[0m         \u001b[0mpre_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1712\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpre_doc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1435\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_alias_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1437\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1438\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1439\u001b[0m             \u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_grab_next_args\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    402\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mseg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mseg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    382\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'plot'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m             raise ValueError(\"x and y can be no greater than 2-D, but have \"\n\u001b[0;32m--> 246\u001b[0;31m                              \"shapes {} and {}\".format(x.shape, y.shape))\n\u001b[0m\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: x and y can be no greater than 2-D, but have shapes (1,) and (1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1)"
     ]
    }
   ],
   "source": [
    "plt.plot(loss_holder)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSUEAzoREQJ8f8Bfjh6bfLHRtwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f53a1c294a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_holder[:raw.shape[0]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('fc1.0.weight', \n",
       "              1.00000e-02 *\n",
       "                  nan     nan     nan  ...      nan     nan     nan\n",
       "               7.3819 -4.0287 -6.9461  ...   6.9727  2.0407 -6.6162\n",
       "                  nan     nan     nan  ...      nan     nan     nan\n",
       "                        ...             ⋱             ...          \n",
       "                  nan     nan     nan  ...      nan     nan     nan\n",
       "                  nan     nan     nan  ...      nan     nan     nan\n",
       "                  nan     nan     nan  ...      nan     nan     nan\n",
       "              [torch.FloatTensor of size 100x154]), ('fc1.0.bias', \n",
       "              1.00000e-02 *\n",
       "                   nan\n",
       "               -0.4525\n",
       "                   nan\n",
       "                6.7199\n",
       "                   nan\n",
       "                   nan\n",
       "                   nan\n",
       "                   nan\n",
       "                   nan\n",
       "                   nan\n",
       "                   nan\n",
       "                   nan\n",
       "                   nan\n",
       "                   nan\n",
       "                   nan\n",
       "               -0.6064\n",
       "                   nan\n",
       "                   nan\n",
       "                4.0657\n",
       "                   nan\n",
       "               -5.9879\n",
       "                   nan\n",
       "                   nan\n",
       "                   nan\n",
       "                1.0131\n",
       "                   nan\n",
       "                   nan\n",
       "                   nan\n",
       "                   nan\n",
       "                3.0417\n",
       "                   nan\n",
       "                   nan\n",
       "                   nan\n",
       "                   nan\n",
       "               -3.8372\n",
       "                   nan\n",
       "                5.6243\n",
       "                6.3459\n",
       "                   nan\n",
       "                   nan\n",
       "                   nan\n",
       "                   nan\n",
       "                   nan\n",
       "                   nan\n",
       "                   nan\n",
       "                   nan\n",
       "                   nan\n",
       "                   nan\n",
       "                   nan\n",
       "                   nan\n",
       "                   nan\n",
       "                   nan\n",
       "               -6.9160\n",
       "                   nan\n",
       "               -1.7852\n",
       "                   nan\n",
       "                   nan\n",
       "               -4.3308\n",
       "                   nan\n",
       "                   nan\n",
       "                   nan\n",
       "               -1.5717\n",
       "                   nan\n",
       "                   nan\n",
       "                   nan\n",
       "                   nan\n",
       "                   nan\n",
       "                   nan\n",
       "               -0.9920\n",
       "                   nan\n",
       "               -6.7035\n",
       "                   nan\n",
       "                   nan\n",
       "                   nan\n",
       "                   nan\n",
       "                   nan\n",
       "                   nan\n",
       "                   nan\n",
       "                   nan\n",
       "                   nan\n",
       "                   nan\n",
       "                   nan\n",
       "                5.3907\n",
       "                   nan\n",
       "                   nan\n",
       "                   nan\n",
       "                   nan\n",
       "                   nan\n",
       "                   nan\n",
       "                   nan\n",
       "                   nan\n",
       "                   nan\n",
       "                   nan\n",
       "                   nan\n",
       "                   nan\n",
       "                0.4443\n",
       "                   nan\n",
       "                   nan\n",
       "                   nan\n",
       "                   nan\n",
       "              [torch.FloatTensor of size 100]), ('fc1.2.weight', \n",
       "                nan   nan   nan  ...    nan   nan   nan\n",
       "                nan   nan   nan  ...    nan   nan   nan\n",
       "                nan   nan   nan  ...    nan   nan   nan\n",
       "                     ...          ⋱          ...       \n",
       "                nan   nan   nan  ...    nan   nan   nan\n",
       "                nan   nan   nan  ...    nan   nan   nan\n",
       "                nan   nan   nan  ...    nan   nan   nan\n",
       "              [torch.FloatTensor of size 80x100]), ('fc1.2.bias', \n",
       "              nan\n",
       "              nan\n",
       "              nan\n",
       "              nan\n",
       "              nan\n",
       "              nan\n",
       "              nan\n",
       "              nan\n",
       "              nan\n",
       "              nan\n",
       "              nan\n",
       "              nan\n",
       "              nan\n",
       "              nan\n",
       "              nan\n",
       "              nan\n",
       "              nan\n",
       "              nan\n",
       "              nan\n",
       "              nan\n",
       "              nan\n",
       "              nan\n",
       "              nan\n",
       "              nan\n",
       "              nan\n",
       "              nan\n",
       "              nan\n",
       "              nan\n",
       "              nan\n",
       "              nan\n",
       "              nan\n",
       "              nan\n",
       "              nan\n",
       "              nan\n",
       "              nan\n",
       "              nan\n",
       "              nan\n",
       "              nan\n",
       "              nan\n",
       "              nan\n",
       "              nan\n",
       "              nan\n",
       "              nan\n",
       "              nan\n",
       "              nan\n",
       "              nan\n",
       "              nan\n",
       "              nan\n",
       "              nan\n",
       "              nan\n",
       "              nan\n",
       "              nan\n",
       "              nan\n",
       "              nan\n",
       "              nan\n",
       "              nan\n",
       "              nan\n",
       "              nan\n",
       "              nan\n",
       "              nan\n",
       "              nan\n",
       "              nan\n",
       "              nan\n",
       "              nan\n",
       "              nan\n",
       "              nan\n",
       "              nan\n",
       "              nan\n",
       "              nan\n",
       "              nan\n",
       "              nan\n",
       "              nan\n",
       "              nan\n",
       "              nan\n",
       "              nan\n",
       "              nan\n",
       "              nan\n",
       "              nan\n",
       "              nan\n",
       "              nan\n",
       "              [torch.FloatTensor of size 80])])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
