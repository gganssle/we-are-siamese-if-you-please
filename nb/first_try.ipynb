{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cluster ID</th>\n",
       "      <th>Id</th>\n",
       "      <th>Site name</th>\n",
       "      <th>Address</th>\n",
       "      <th>Zip</th>\n",
       "      <th>Phone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>salvation army - temple / salvation army</td>\n",
       "      <td>1 n ogden ave</td>\n",
       "      <td>nan</td>\n",
       "      <td>2262649.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>salvation army - temple / salvation army</td>\n",
       "      <td>1 n ogden ave</td>\n",
       "      <td>nan</td>\n",
       "      <td>2262649.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>215</td>\n",
       "      <td>salvation army temple</td>\n",
       "      <td>1 n. ogden</td>\n",
       "      <td>nan</td>\n",
       "      <td>2262649.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>509</td>\n",
       "      <td>salvation army - temple / salvation army</td>\n",
       "      <td>1 n ogden ave</td>\n",
       "      <td>nan</td>\n",
       "      <td>2262649.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>510</td>\n",
       "      <td>salvation army - temple / salvation army</td>\n",
       "      <td>1 n ogden ave</td>\n",
       "      <td>nan</td>\n",
       "      <td>2262649.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cluster ID   Id                                 Site name        Address  \\\n",
       "0           0    0  salvation army - temple / salvation army  1 n ogden ave   \n",
       "1           0    1  salvation army - temple / salvation army  1 n ogden ave   \n",
       "2           0  215                     salvation army temple     1 n. ogden   \n",
       "3           0  509  salvation army - temple / salvation army  1 n ogden ave   \n",
       "4           0  510  salvation army - temple / salvation army  1 n ogden ave   \n",
       "\n",
       "   Zip      Phone  \n",
       "0  nan  2262649.0  \n",
       "1  nan  2262649.0  \n",
       "2  nan  2262649.0  \n",
       "3  nan  2262649.0  \n",
       "4  nan  2262649.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = pd.read_csv('../dat/schools_w_clusters.csv')\n",
    "raw = raw[['Cluster ID', 'Id', 'Site name', 'Address', 'Zip', 'Phone']]\n",
    "raw['Zip'] = raw['Zip'].astype(str)\n",
    "raw['Phone'] = raw['Phone'].astype(str)\n",
    "raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name max len = 95\n",
      "address max len = 43\n",
      "Zip max len = 7\n",
      "phone max len = 9\n"
     ]
    }
   ],
   "source": [
    "print('name max len =', raw['Site name'].str.len().max())\n",
    "print('address max len =', raw['Address'].str.len().max())\n",
    "print('Zip max len =', raw['Zip'].str.len().max())\n",
    "print('phone max len =', raw['Phone'].str.len().max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for a total of max length 154"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## defs\n",
    "The following insanity is how we need to convert into a useable Torch tensor of correct size and Variable...ness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.0256  0.3088  0.0052  0.3363  0.2279  0.8210  0.0076  0.8412  0.8407  0.6581\n",
       "[torch.FloatTensor of size 1x10]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Variable(torch.from_numpy(np.random.rand(10)).float()).view(1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend_to_length(string_to_expand, length):\n",
    "    extension = '~' * (length-len(string_to_expand))\n",
    "    return string_to_expand + extension\n",
    "\n",
    "def record_formatter(record):\n",
    "    name = extend_to_length(record['Site name'], 95)\n",
    "    addr = extend_to_length(record['Address'], 43)\n",
    "    zipp = extend_to_length(record['Zip'], 7)\n",
    "    phon = extend_to_length(record['Phone'], 9)\n",
    "    \n",
    "    strings = list(''.join((name, addr, zipp, phon)))\n",
    "    characters = np.array(list(map(ord, strings)))\n",
    "    \n",
    "    return Variable(torch.from_numpy(characters).float()).view(1,len(characters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        self.dense1 = nn.Sequential(\n",
    "            nn.Linear(154,100),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(100,50))\n",
    "\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(50,40),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(40, 10),\n",
    "            nn.Linear(10, 2))\n",
    "\n",
    "    def forward_once(self, x):\n",
    "        output = self.dense1(x)\n",
    "        output = output.view(output.size()[0], -1)\n",
    "        output = self.fc1(output)\n",
    "        return output\n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        output1 = self.forward_once(input1)\n",
    "        output2 = self.forward_once(input2)\n",
    "        return output1, output2\n",
    "    \n",
    "class ContrastiveLoss(torch.nn.Module):\n",
    "    def __init__(self, margin=1.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, x0, x1, y):\n",
    "        # euclidian distance\n",
    "        diff = x0 - x1\n",
    "        dist_sq = torch.sum(torch.pow(diff, 2), 1)\n",
    "        dist = torch.sqrt(dist_sq)\n",
    "\n",
    "        mdist = self.margin - dist\n",
    "        dist = torch.clamp(mdist, min=0.0)\n",
    "        loss = y * dist_sq + (1 - y) * torch.pow(dist, 2)\n",
    "        loss = torch.sum(loss) / 2.0 / x0.size()[0]\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpt1 = record_formatter(raw.iloc[0])\n",
    "inpt2 = record_formatter(raw.iloc[1])\n",
    "\n",
    "#print(inpt1)\n",
    "#print(inpt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SiameseNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       " -1.7514 -2.0703\n",
       " [torch.FloatTensor of size 1x2], Variable containing:\n",
       " -1.7514 -2.0703\n",
       " [torch.FloatTensor of size 1x2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.forward(inpt1, inpt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = ContrastiveLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.forward(inpt1, inpt2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 31255\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inpt3 = record_formatter(raw.iloc[2])\n",
    "\n",
    "loss.forward(inpt1, inpt3, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2693, 6)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(740,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw['Cluster ID'].unique().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = SiameseNetwork()\n",
    "loss  = ContrastiveLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for epoch 0 is 19633.0\n",
      "loss for epoch 1 is 19633.0\n",
      "loss for epoch 2 is 19633.0\n",
      "loss for epoch 3 is 19633.0\n",
      "loss for epoch 4 is 19633.0\n",
      "loss for epoch 5 is 19633.0\n",
      "loss for epoch 6 is 19633.0\n",
      "loss for epoch 7 is 19633.0\n",
      "loss for epoch 8 is 19633.0\n",
      "loss for epoch 9 is 19633.0\n",
      "loss for epoch 10 is 19633.0\n",
      "loss for epoch 11 is 19633.0\n",
      "loss for epoch 12 is 19633.0\n",
      "loss for epoch 13 is 19633.0\n",
      "loss for epoch 14 is 19633.0\n",
      "loss for epoch 15 is 19633.0\n",
      "loss for epoch 16 is 19633.0\n",
      "loss for epoch 17 is 19633.0\n",
      "loss for epoch 18 is 19633.0\n",
      "loss for epoch 19 is 19633.0\n",
      "loss for epoch 20 is 19633.0\n",
      "loss for epoch 21 is 19633.0\n",
      "loss for epoch 22 is 19633.0\n",
      "loss for epoch 23 is 19633.0\n",
      "loss for epoch 24 is 19633.0\n",
      "loss for epoch 25 is 19633.0\n",
      "loss for epoch 26 is 19633.0\n",
      "loss for epoch 27 is 19633.0\n",
      "loss for epoch 28 is 19633.0\n",
      "loss for epoch 29 is 19633.0\n",
      "loss for epoch 30 is 19633.0\n",
      "loss for epoch 31 is 19633.0\n",
      "loss for epoch 32 is 19633.0\n",
      "loss for epoch 33 is 19633.0\n",
      "loss for epoch 34 is 19633.0\n",
      "loss for epoch 35 is 19633.0\n",
      "loss for epoch 36 is 19633.0\n",
      "loss for epoch 37 is 19633.0\n",
      "loss for epoch 38 is 19633.0\n",
      "loss for epoch 39 is 19633.0\n",
      "loss for epoch 40 is 19633.0\n",
      "loss for epoch 41 is 19633.0\n",
      "loss for epoch 42 is 19633.0\n",
      "loss for epoch 43 is 19633.0\n",
      "loss for epoch 44 is 19633.0\n",
      "loss for epoch 45 is 19633.0\n",
      "loss for epoch 46 is 19633.0\n",
      "loss for epoch 47 is 19633.0\n",
      "loss for epoch 48 is 19633.0\n",
      "loss for epoch 49 is 19633.0\n",
      "loss for epoch 50 is 19633.0\n",
      "loss for epoch 51 is 19633.0\n",
      "loss for epoch 52 is 19633.0\n",
      "loss for epoch 53 is 19633.0\n",
      "loss for epoch 54 is 19633.0\n",
      "loss for epoch 55 is 19633.0\n",
      "loss for epoch 56 is 19633.0\n",
      "loss for epoch 57 is 19633.0\n",
      "loss for epoch 58 is 19633.0\n",
      "loss for epoch 59 is 19633.0\n",
      "loss for epoch 60 is 19633.0\n",
      "loss for epoch 61 is 19633.0\n",
      "loss for epoch 62 is 19633.0\n",
      "loss for epoch 63 is 19633.0\n",
      "loss for epoch 64 is 19633.0\n",
      "loss for epoch 65 is 19633.0\n",
      "loss for epoch 66 is 19633.0\n",
      "loss for epoch 67 is 19633.0\n",
      "loss for epoch 68 is 19633.0\n",
      "loss for epoch 69 is 19633.0\n",
      "loss for epoch 70 is 19633.0\n",
      "loss for epoch 71 is 19633.0\n",
      "loss for epoch 72 is 19633.0\n",
      "loss for epoch 73 is 19633.0\n",
      "loss for epoch 74 is 19633.0\n",
      "loss for epoch 75 is 19633.0\n",
      "loss for epoch 76 is 19633.0\n",
      "loss for epoch 77 is 19633.0\n",
      "loss for epoch 78 is 19633.0\n",
      "loss for epoch 79 is 19633.0\n",
      "loss for epoch 80 is 19633.0\n",
      "loss for epoch 81 is 19633.0\n",
      "loss for epoch 82 is 19633.0\n",
      "loss for epoch 83 is 19633.0\n",
      "loss for epoch 84 is 19633.0\n",
      "loss for epoch 85 is 19633.0\n",
      "loss for epoch 86 is 19633.0\n",
      "loss for epoch 87 is 19633.0\n",
      "loss for epoch 88 is 19633.0\n",
      "loss for epoch 89 is 19633.0\n",
      "loss for epoch 90 is 19633.0\n",
      "loss for epoch 91 is 19633.0\n",
      "loss for epoch 92 is 19633.0\n",
      "loss for epoch 93 is 19633.0\n",
      "loss for epoch 94 is 19633.0\n",
      "loss for epoch 95 is 19633.0\n",
      "loss for epoch 96 is 19633.0\n",
      "loss for epoch 97 is 19633.0\n",
      "loss for epoch 98 is 19633.0\n",
      "loss for epoch 99 is 19633.0\n",
      "loss for epoch 100 is 19633.0\n",
      "loss for epoch 101 is 19633.0\n",
      "loss for epoch 102 is 19633.0\n",
      "loss for epoch 103 is 19633.0\n",
      "loss for epoch 104 is 19633.0\n",
      "loss for epoch 105 is 19633.0\n",
      "loss for epoch 106 is 19633.0\n",
      "loss for epoch 107 is 19633.0\n",
      "loss for epoch 108 is 19633.0\n",
      "loss for epoch 109 is 19633.0\n",
      "loss for epoch 110 is 19633.0\n",
      "loss for epoch 111 is 19633.0\n",
      "loss for epoch 112 is 19633.0\n",
      "loss for epoch 113 is 19633.0\n",
      "loss for epoch 114 is 19633.0\n",
      "loss for epoch 115 is 19633.0\n",
      "loss for epoch 116 is 19633.0\n",
      "loss for epoch 117 is 19633.0\n",
      "loss for epoch 118 is 19633.0\n",
      "loss for epoch 119 is 19633.0\n",
      "loss for epoch 120 is 19633.0\n",
      "loss for epoch 121 is 19633.0\n",
      "loss for epoch 122 is 19633.0\n",
      "loss for epoch 123 is 19633.0\n",
      "loss for epoch 124 is 19633.0\n",
      "loss for epoch 125 is 19633.0\n",
      "loss for epoch 126 is 19633.0\n",
      "loss for epoch 127 is 19633.0\n",
      "loss for epoch 128 is 19633.0\n",
      "loss for epoch 129 is 19633.0\n",
      "loss for epoch 130 is 19633.0\n",
      "loss for epoch 131 is 19633.0\n",
      "loss for epoch 132 is 19633.0\n",
      "loss for epoch 133 is 19633.0\n",
      "loss for epoch 134 is 19633.0\n",
      "loss for epoch 135 is 19633.0\n",
      "loss for epoch 136 is 19633.0\n",
      "loss for epoch 137 is 19633.0\n",
      "loss for epoch 138 is 19633.0\n",
      "loss for epoch 139 is 19633.0\n",
      "loss for epoch 140 is 19633.0\n",
      "loss for epoch 141 is 19633.0\n",
      "loss for epoch 142 is 19633.0\n",
      "loss for epoch 143 is 19633.0\n",
      "loss for epoch 144 is 19633.0\n",
      "loss for epoch 145 is 19633.0\n",
      "loss for epoch 146 is 19633.0\n",
      "loss for epoch 147 is 19633.0\n",
      "loss for epoch 148 is 19633.0\n",
      "loss for epoch 149 is 19633.0\n",
      "loss for epoch 150 is 19633.0\n",
      "loss for epoch 151 is 19633.0\n",
      "loss for epoch 152 is 19633.0\n",
      "loss for epoch 153 is 19633.0\n",
      "loss for epoch 154 is 19633.0\n",
      "loss for epoch 155 is 19633.0\n",
      "loss for epoch 156 is 19633.0\n",
      "loss for epoch 157 is 19633.0\n",
      "loss for epoch 158 is 19633.0\n",
      "loss for epoch 159 is 19633.0\n",
      "loss for epoch 160 is 19633.0\n",
      "loss for epoch 161 is 19633.0\n",
      "loss for epoch 162 is 19633.0\n",
      "loss for epoch 163 is 19633.0\n",
      "loss for epoch 164 is 19633.0\n",
      "loss for epoch 165 is 19633.0\n",
      "loss for epoch 166 is 19633.0\n",
      "loss for epoch 167 is 19633.0\n",
      "loss for epoch 168 is 19633.0\n",
      "loss for epoch 169 is 19633.0\n",
      "loss for epoch 170 is 19633.0\n",
      "loss for epoch 171 is 19633.0\n",
      "loss for epoch 172 is 19633.0\n",
      "loss for epoch 173 is 19633.0\n",
      "loss for epoch 174 is 19633.0\n",
      "loss for epoch 175 is 19633.0\n",
      "loss for epoch 176 is 19633.0\n",
      "loss for epoch 177 is 19633.0\n",
      "loss for epoch 178 is 19633.0\n",
      "loss for epoch 179 is 19633.0\n",
      "loss for epoch 180 is 19633.0\n",
      "loss for epoch 181 is 19633.0\n",
      "loss for epoch 182 is 19633.0\n",
      "loss for epoch 183 is 19633.0\n",
      "loss for epoch 184 is 19633.0\n",
      "loss for epoch 185 is 19633.0\n",
      "loss for epoch 186 is 19633.0\n",
      "loss for epoch 187 is 19633.0\n",
      "loss for epoch 188 is 19633.0\n",
      "loss for epoch 189 is 19633.0\n",
      "loss for epoch 190 is 19633.0\n",
      "loss for epoch 191 is 19633.0\n",
      "loss for epoch 192 is 19633.0\n",
      "loss for epoch 193 is 19633.0\n",
      "loss for epoch 194 is 19633.0\n",
      "loss for epoch 195 is 19633.0\n",
      "loss for epoch 196 is 19633.0\n",
      "loss for epoch 197 is 19633.0\n",
      "loss for epoch 198 is 19633.0\n",
      "loss for epoch 199 is 19633.0\n",
      "CPU times: user 29min 46s, sys: 4.91 s, total: 29min 51s\n",
      "Wall time: 7min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "loss_holder = []\n",
    "\n",
    "for epoch in range(200):\n",
    "    for i in range(raw.shape[0]-1):\n",
    "        # build data pairs\n",
    "        inpt1 = record_formatter(raw.iloc[i])\n",
    "        inpt2 = record_formatter(raw.iloc[i+1])\n",
    "        label = 1 if (raw.iloc[i]['Cluster ID'] == raw.iloc[i+1]['Cluster ID']) else 0\n",
    "        \n",
    "        # forward\n",
    "        otpt1, otpt2 = model.forward(inpt1, inpt2)\n",
    "        optimizer.zero_grad()\n",
    "        loss_calc = loss.forward(inpt1, inpt2, label)\n",
    "        # reassign loss requiring gradient\n",
    "        loss_calc = Variable(loss_calc.data, requires_grad=True)\n",
    "        \n",
    "        # backward\n",
    "        loss_calc.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # console.log\n",
    "        loss_holder.append(loss_calc.data[0])\n",
    "        if i == raw.shape[0]-2:\n",
    "            print('loss for epoch', epoch, 'is', loss_calc.data[0])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlf8DjJF051g54vEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1820f7e7b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_holder)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
